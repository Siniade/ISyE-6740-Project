{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "deb8911d",
   "metadata": {},
   "source": [
    "## Illustrate how to tranform data matrix into pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fa2a297",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85632852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/sanchitdighe/Documents/GaTech/Sem 2/ISyE 6740 - CDA/Project/archive'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "filepath = 'Documents/GaTech/Sem 2/ISyE 6740 - CDA/Project/archive'\n",
    "os.chdir(os.path.expanduser('~/'))\n",
    "os.chdir(filepath)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23464c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.listdir('Happy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5327f3af",
   "metadata": {},
   "source": [
    "### Read Images from File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb41726d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Happy\n",
      "Fear\n",
      "Neutral\n",
      "Angry\n",
      "Disgust\n"
     ]
    }
   ],
   "source": [
    "#X_data = {'Happy':[], 'Fear':[], 'Neutral':[], 'Angry':[], 'Disgust':[]}\n",
    "X_data = []\n",
    "y = []\n",
    "for files in os.listdir():\n",
    "    if not files.startswith('.'):\n",
    "        print(files)\n",
    "        #print(os.listdir(files))\n",
    "        for image in os.listdir(files):\n",
    "            path = f\"{files}/{image}\"\n",
    "            data = cv2.imread(path) # Reads image in BGR format\n",
    "            data = cv2.cvtColor(data, cv2.COLOR_BGR2GRAY) # Convert to Grayscale\n",
    "            X_data.append (data)\n",
    "        for j in range(len(os.listdir(files))):\n",
    "            y.append(files)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9df88d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = np.asarray(X_data).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b710051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2       , 0.18431373, 0.21568628, ..., 0.2509804 , 0.27058825,\n",
       "        0.28627452],\n",
       "       [0.29411766, 0.30980393, 0.23529412, ..., 0.84313726, 0.8156863 ,\n",
       "        0.78431374],\n",
       "       [0.8509804 , 0.9254902 , 0.9372549 , ..., 0.8235294 , 0.8156863 ,\n",
       "        0.79607844],\n",
       "       ...,\n",
       "       [0.24705882, 0.25882354, 0.27450982, ..., 0.21568628, 0.23921569,\n",
       "        0.22745098],\n",
       "       [0.75686276, 0.78039217, 0.6901961 , ..., 0.25490198, 0.24313726,\n",
       "        0.23921569],\n",
       "       [0.75686276, 0.78039217, 0.6901961 , ..., 0.25490198, 0.24313726,\n",
       "        0.23921569]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data.shape\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "X_data = X_data/255\n",
    "X_data[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05dfcb8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(48, 48)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"Happy/Training_77412.jpg\"\n",
    "data = cv2.imread(path)\n",
    "data = cv2.cvtColor(data, cv2.COLOR_BGR2GRAY)\n",
    "plt.imshow(data, cmap='Greys_r')\n",
    "plt.show()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b164188e",
   "metadata": {},
   "source": [
    "### Split Data into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3411b1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y, test_size = 0.25, random_state = 42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04d8714",
   "metadata": {},
   "source": [
    "#### Convert Y labels to Numpy Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "014d379f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.asarray(y_train)\n",
    "Y_test = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436fd671",
   "metadata": {},
   "source": [
    "## Decompose Training Images using CP and Tucker Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a670304f",
   "metadata": {},
   "source": [
    "#### Import Tensorly Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5f9b297",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorly as tl\n",
    "from tensorly.decomposition import parafac\n",
    "from tensorly.decomposition import tucker\n",
    "from tensorly.tenalg import mode_dot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d882d8f9",
   "metadata": {},
   "source": [
    "#### Decompose Training Set with CP & Tucker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fe06956",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cp = np.empty(shape=(48,48, len(X_train)),dtype='float32') #CP\n",
    "rank_cp = 5\n",
    "\n",
    "rank_tuck = [5,5]\n",
    "X_train_tuck = np.empty(shape=(rank_tuck[0], rank_tuck[1], len(X_train)), dtype='float32') #Tucker\n",
    "\n",
    "for i in range(len(X_train)): # i iterates through all images\n",
    "    # Specify the tensor\n",
    "    X = tl.tensor(X_train[i].astype(float))\n",
    "    \n",
    "    # Perform CP decompositon using TensorLy\n",
    "    factors_tl = parafac(X, rank=rank_cp)\n",
    "    a, b = factors_tl\n",
    "    b1 = []\n",
    "    b2 = []\n",
    "    for j in range(rank_cp): # j iterates through all ranks\n",
    "        b1 = b[0][:,j].reshape(-1,1).astype(np.float32)\n",
    "        b2 = b[1][:,j].reshape(-1,1).astype(np.float32)\n",
    "        X_train_cp[:,:,i] = X_train_cp[:,:,i] + np.tensordot(b1, b2.T, axes=1)\n",
    "    \n",
    "    # Perform Tucker Decomposition using TensorLy\n",
    "    X_train_tuck[:,:,i], factors = tucker(X, rank=rank_tuck)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a6d156",
   "metadata": {},
   "source": [
    "#### Decompose Testing Set with CP\n",
    "* For Tucker, we'll use the Tucker factorizing matrices computed above from training set to compute the core test matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2673b879",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_cp = np.empty(shape=(48,48, len(X_test)),dtype='float32') #CP\n",
    "\n",
    "#core_test = np.empty(shape=(rank_tuck[0], rank_tuck[1], len(X_test)), dtype='float32') #Tucker\n",
    "\n",
    "for i in range(len(X_test)): # i iterates through all images\n",
    "    # Specify the tensor and the rank\n",
    "    X, rank = tl.tensor(X_test[i].astype(float)), 5\n",
    "    \n",
    "    # Perform CP decompositon using TensorLy\n",
    "    factors_tl = parafac(X, rank=rank_cp) \n",
    "    a, b = factors_tl\n",
    "    b1 = []\n",
    "    b2 = []\n",
    "    for j in range(rank_cp): # j iterates through all ranks\n",
    "        b1 = b[0][:,j].reshape(-1,1).astype(np.float32)\n",
    "        b2 = b[1][:,j].reshape(-1,1).astype(np.float32)\n",
    "        X_test_cp[:,:,i] = X_test_cp[:,:,i] + np.tensordot(b1, b2.T, axes=1)\n",
    "    \n",
    "    # Perform Tucker Decomposition using TensorLy\n",
    "    #rank_tuck = [5,5]\n",
    "    #core_test[:,:,i], factors = tucker(X, rank=rank_tuck)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7605da3",
   "metadata": {},
   "source": [
    "* Flatten train and test inputs of CP Decomposed Images for Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7fda73df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cp = X_train_cp.reshape(X_train_cp.shape[2],-1)\n",
    "X_test_cp = X_test_cp.reshape(X_test_cp.shape[2],-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aaac70f",
   "metadata": {},
   "source": [
    "* Compute Test Inputs for Tucker Decomposed Images using Tensor-Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85915ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "factors_tuck = np.asarray(factors)\n",
    "#X_test_tuck = np.zeros((len(X_test),5,5))\n",
    "X_test_tuck =[]\n",
    "for i in range(len(X_test)):\n",
    "    X = tl.tensor(X_test[i].astype(float))\n",
    "    c1 = mode_dot(X, factors_tuck[0],0, transpose=True)\n",
    "    \n",
    "    X_test_tuck.append(mode_dot(c1, factors_tuck[1],1, transpose=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3a30ef",
   "metadata": {},
   "source": [
    "* Flatten train and test inputs of Tucker Decomposed Images for Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "246bf795",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tuck = X_train_tuck.reshape(X_train_tuck.shape[2],-1)\n",
    "X_test_tuck = np.asarray(X_test_tuck)\n",
    "X_test_tuck = X_test_tuck.reshape(X_test_tuck.shape[0],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afe23ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(X_train[1], cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb38cfd1",
   "metadata": {},
   "source": [
    "### Fit RandomForest Classifier on CP Decomposed Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "51b8ac54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=500, random_state=42)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Instantiate model with 100 decision trees\n",
    "rf_cp = RandomForestClassifier(n_estimators = 500, random_state = 42, max_depth=6)\n",
    "# Train the model on training data\n",
    "rf_cp.fit(X_train_cp, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1789d9a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, ..., 3, 3, 3])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cp.predict(X_test_cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5638b1ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4069684759421664"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(rf_cp.predict(X_test_cp)==Y_test)/len(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dc0172",
   "metadata": {},
   "source": [
    "### Fit RandomForest Classifier on Tucker Decomposed Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "af169fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=500, random_state=42)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Random Forest using Tucker Decomposition\n",
    "\n",
    "# Instantiate model with 100 decision trees\n",
    "rf_tuck = RandomForestClassifier(n_estimators = 500, random_state = 42, max_depth=6)\n",
    "# Train the model on training data\n",
    "rf_tuck.fit(X_train_tuck, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "161fea76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, ..., 3, 3, 3])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_tuck.predict(X_test_tuck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8d4b3b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40388717705617444"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(rf_tuck.predict(X_test_tuck)==Y_test)/len(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "54d1d2cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4219, 2304)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3615af7",
   "metadata": {},
   "source": [
    "### Fit RandomForest Classifier on Non-Decomposed Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3298880",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0],-1)\n",
    "X_test = X_test.reshape(X_test.shape[0],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1e7f84a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=500, random_state=42)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Random Forest using Tucker Decomposition\n",
    "\n",
    "# Instantiate model with 100 decision trees\n",
    "rf = RandomForestClassifier(n_estimators = 500, random_state = 42, max_depth=6)\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "81ed00e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 4, ..., 1, 3, 3])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "02291620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5479971557241052"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(rf.predict(X_test)==Y_test)/len(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fb2b62",
   "metadata": {},
   "source": [
    "### Fit Multi-Layer Perceptron Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40d8c8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.5092834004898475\n",
      "Testing accuracy:  0.46622422374970374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sanchitdighe/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "#import pickle5 as pickle\n",
    "\n",
    "nn = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(5, 5, 5), random_state=42)\n",
    "\n",
    "nn.fit(X_train, Y_train)\n",
    "\n",
    "#with open('nnmodel.pkl','wb') as f:\n",
    "#    pickle.dump(nn,f)\n",
    "\n",
    "print('Training accuracy: ', nn.score(X_train, Y_train))\n",
    "print('Testing accuracy: ', nn.score(X_test, Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082059d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e54401",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1526719",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['emotion'].mask(df['emotion'] == 0, 'Anger', inplace=True)\n",
    "df['emotion'].mask(df['emotion'] == 1, 'Disgust', inplace=True)\n",
    "df['emotion'].mask(df['emotion'] == 2, 'Fear', inplace=True)\n",
    "df['emotion'].mask(df['emotion'] == 3, 'Happy', inplace=True)\n",
    "df['emotion'].mask(df['emotion'] == 4, 'Sad', inplace=True)\n",
    "df['emotion'].mask(df['emotion'] == 5, 'Surprise', inplace=True)\n",
    "df['emotion'].mask(df['emotion'] == 6, 'Neutral', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e84efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434f44d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f003abd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    r = np.random.randint((1), 24000, 1)[0]\n",
    "    plt.figure()\n",
    "    img = df.iloc[r]['pixels'].split()\n",
    "    img = [int(i) for i in img]\n",
    "    img = np.array(img)\n",
    "    img = img.reshape(48,48)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.xlabel(df.iloc[r]['emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd51ee2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
